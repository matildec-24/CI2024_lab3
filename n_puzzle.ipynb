{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple, deque\n",
    "from heapq import heappush, heappop\n",
    "from random import choice\n",
    "from tqdm import tqdm\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puzzle size\n",
    "PUZZLE_DIM = 4\n",
    "RANDOMIZE_STEPS = 10_000\n",
    "\n",
    "# Action to represent the swap between two positions\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhattan distance function (heuristic)\n",
    "def manhattan_distance(state, goal_state):\n",
    "    distance = 0\n",
    "    goal_state_flat = np.array(goal_state).flatten()\n",
    "    goal_state_flat = goal_state_flat.tolist()\n",
    "    for i in range(len(state)):\n",
    "        for j in range(len(state[i])):\n",
    "            if state[i][j] != 0:  # Do not consider the empty space\n",
    "                goal_pos = divmod(goal_state_flat.index(state[i][j]), len(state))\n",
    "                distance += abs(i - goal_pos[0]) + abs(j - goal_pos[1])\n",
    "    return distance\n",
    "\n",
    "# Find the available actions (possible moves)\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "# Perform an action on the state\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform A* Search\n",
    "def A_star(start_state, goal_state):\n",
    "    # Initialize the frontier\n",
    "    frontier = []\n",
    "\n",
    "    # Initial cost and heuristic estimate\n",
    "    g = 0  \n",
    "    h = manhattan_distance(start_state, goal_state) \n",
    "    f = g + h  # Total estimated cost\n",
    "\n",
    "    # Push the initial state into the frontier\n",
    "    heappush(frontier, (f, start_state.tobytes(), g, None))\n",
    "\n",
    "    # Dictionaries to store predecessors and costs\n",
    "    came_from = {start_state.tobytes(): None}  # Maps a state to its predecessor (for reconstructing the path)\n",
    "    g_score = {start_state.tobytes(): 0}  # Cost to reach each state from the start\n",
    "\n",
    "    # Set to track explored states to prevent revisits\n",
    "    explored = set()\n",
    "\n",
    "    while frontier:\n",
    "        # Extract the state with the smallest f-score\n",
    "        _, current_bytes, current_g, parent = heappop(frontier)\n",
    "        current_state = np.frombuffer(current_bytes, dtype=start_state.dtype).reshape(start_state.shape)\n",
    "\n",
    "        # If the state has already been explored, skip it\n",
    "        if current_bytes in explored:\n",
    "            continue\n",
    "        explored.add(current_bytes) \n",
    "        came_from[current_bytes] = parent  # Record the parent state\n",
    "\n",
    "        # Check if the current state is the goal state\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            cost = len(explored)  # The total number of explored states\n",
    "            return reconstruct_path(came_from, current_bytes), cost\n",
    "\n",
    "        # Explore the neighbors of the current state\n",
    "        for act in available_actions(current_state):\n",
    "            neighbor = do_action(current_state, act)  # Apply action to get the neighbor state\n",
    "            neighbor_bytes = neighbor.tobytes()\n",
    "\n",
    "            # Calculate the tentative g-score (path cost through the current state)\n",
    "            tentative_g = current_g + 1 \n",
    "            if neighbor_bytes not in g_score or tentative_g < g_score[neighbor_bytes]:\n",
    "                # If this path to the neighbor is shorter or unvisited, record it\n",
    "                g_score[neighbor_bytes] = tentative_g\n",
    "                f_score = tentative_g + manhattan_distance(neighbor, goal_state)\n",
    "                heappush(frontier, (f_score, neighbor_bytes, tentative_g, current_bytes))\n",
    "\n",
    "    return None, len(explored) \n",
    "\n",
    "\n",
    "# Reconstructs the path from the start state to the goal state using the predecessor dictionary\n",
    "def reconstruct_path(came_from, current):\n",
    "    path = []\n",
    "    while current is not None:\n",
    "        path.append(current)  # Add the current state to the path\n",
    "        current = came_from[current]  # Move to the predecessor\n",
    "    return path[::-1]  # Return the path in the correct order, from start to goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 10000/10000 [00:00<00:00, 76335.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stato iniziale:\n",
      "[[14  3  1  8]\n",
      " [ 7  2  5 13]\n",
      " [15 11  0 12]\n",
      " [10  6  4  9]]\n",
      "Quality (number of moves): 50\n",
      "Cost (explored states): 839064\n",
      "Solution Path:\n",
      "[[14  3  1  8]\n",
      " [ 7  2  5 13]\n",
      " [15 11  0 12]\n",
      " [10  6  4  9]]\n",
      "[[14  3  1  8]\n",
      " [ 7  2  5 13]\n",
      " [15  0 11 12]\n",
      " [10  6  4  9]]\n",
      "[[14  3  1  8]\n",
      " [ 7  0  5 13]\n",
      " [15  2 11 12]\n",
      " [10  6  4  9]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5  0 13]\n",
      " [15  2 11 12]\n",
      " [10  6  4  9]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5 11 13]\n",
      " [15  2  0 12]\n",
      " [10  6  4  9]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5 11 13]\n",
      " [15  2  4 12]\n",
      " [10  6  0  9]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5 11 13]\n",
      " [15  2  4 12]\n",
      " [10  6  9  0]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5 11 13]\n",
      " [15  2  4  0]\n",
      " [10  6  9 12]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5 11  0]\n",
      " [15  2  4 13]\n",
      " [10  6  9 12]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5  0 11]\n",
      " [15  2  4 13]\n",
      " [10  6  9 12]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5  4 11]\n",
      " [15  2  0 13]\n",
      " [10  6  9 12]]\n",
      "[[14  3  1  8]\n",
      " [ 7  5  4 11]\n",
      " [15  0  2 13]\n",
      " [10  6  9 12]]\n",
      "[[14  3  1  8]\n",
      " [ 7  0  4 11]\n",
      " [15  5  2 13]\n",
      " [10  6  9 12]]\n",
      "[[14  0  1  8]\n",
      " [ 7  3  4 11]\n",
      " [15  5  2 13]\n",
      " [10  6  9 12]]\n",
      "[[14  1  0  8]\n",
      " [ 7  3  4 11]\n",
      " [15  5  2 13]\n",
      " [10  6  9 12]]\n",
      "[[14  1  4  8]\n",
      " [ 7  3  0 11]\n",
      " [15  5  2 13]\n",
      " [10  6  9 12]]\n",
      "[[14  1  4  8]\n",
      " [ 7  3  2 11]\n",
      " [15  5  0 13]\n",
      " [10  6  9 12]]\n",
      "[[14  1  4  8]\n",
      " [ 7  3  2 11]\n",
      " [15  5 13  0]\n",
      " [10  6  9 12]]\n",
      "[[14  1  4  8]\n",
      " [ 7  3  2  0]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[14  1  4  0]\n",
      " [ 7  3  2  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[14  1  0  4]\n",
      " [ 7  3  2  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[14  1  2  4]\n",
      " [ 7  3  0  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[14  1  2  4]\n",
      " [ 7  0  3  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[14  1  2  4]\n",
      " [ 0  7  3  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[ 0  1  2  4]\n",
      " [14  7  3  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[ 1  0  2  4]\n",
      " [14  7  3  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[ 1  2  0  4]\n",
      " [14  7  3  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [14  7  0  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [14  0  7  8]\n",
      " [15  5 13 11]\n",
      " [10  6  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [14  5  7  8]\n",
      " [15  0 13 11]\n",
      " [10  6  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [14  5  7  8]\n",
      " [15  6 13 11]\n",
      " [10  0  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [14  5  7  8]\n",
      " [15  6 13 11]\n",
      " [ 0 10  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [14  5  7  8]\n",
      " [ 0  6 13 11]\n",
      " [15 10  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 0  5  7  8]\n",
      " [14  6 13 11]\n",
      " [15 10  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  0  7  8]\n",
      " [14  6 13 11]\n",
      " [15 10  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [14  0 13 11]\n",
      " [15 10  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [14 13  0 11]\n",
      " [15 10  9 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [14 13  9 11]\n",
      " [15 10  0 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [14 13  9 11]\n",
      " [15  0 10 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [14 13  9 11]\n",
      " [ 0 15 10 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 0 13  9 11]\n",
      " [14 15 10 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [13  0  9 11]\n",
      " [14 15 10 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [13  9  0 11]\n",
      " [14 15 10 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [13  9 10 11]\n",
      " [14 15  0 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [13  9 10 11]\n",
      " [14  0 15 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [13  9 10 11]\n",
      " [ 0 14 15 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 0  9 10 11]\n",
      " [13 14 15 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9  0 10 11]\n",
      " [13 14 15 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10  0 11]\n",
      " [13 14 15 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11  0]\n",
      " [13 14 15 12]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15  0]]\n"
     ]
    }
   ],
   "source": [
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "    \n",
    "start_state = state\n",
    "goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\n",
    "# Risolvi il puzzle\n",
    "print(\"Initial state:\")\n",
    "print(state)\n",
    "\n",
    "\n",
    "path, cost = A_star(start_state, goal_state)\n",
    "quality = len(path) - 1  # Quality: Number of moves\n",
    "print(f\"Quality (number of moves): {quality}\")\n",
    "print(f\"Cost (explored states): {cost}\")\n",
    "print(\"Solution Path:\")\n",
    "for step in path:\n",
    "    print(np.frombuffer(step, dtype=start_state.dtype).reshape(start_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the full path from start to goal via the meeting point\n",
    "def reconstruct_path_(came_from_start, came_from_goal, meeting_point):\n",
    "    # Path from the start state to the meeting point\n",
    "    path_start = []\n",
    "    current = meeting_point\n",
    "    while current is not None:\n",
    "        path_start.append(current)\n",
    "        current = came_from_start[current]\n",
    "    path_start = path_start[::-1]  # Reverse to get the path in the correct order\n",
    "\n",
    "    # Path from the meeting point to the goal state\n",
    "    path_goal = []\n",
    "    current = came_from_goal[meeting_point]\n",
    "    while current is not None:\n",
    "        path_goal.append(current)\n",
    "        current = came_from_goal[current]\n",
    "\n",
    "    return path_start + path_goal  # Combine the two paths\n",
    "\n",
    "# Perform Bidirectional A* Search\n",
    "def bidirectional_A_star(start_state, goal_state):\n",
    "    # Initialize the frontiers for both directions\n",
    "    frontier_start = []\n",
    "    frontier_goal = []\n",
    "\n",
    "    # Initial costs and heuristic estimates for both directions\n",
    "    g_start, g_goal = 0, 0\n",
    "    h_start = manhattan_distance(start_state, goal_state)\n",
    "    h_goal = manhattan_distance(goal_state, start_state)\n",
    "    f_start = g_start + h_start\n",
    "    f_goal = g_goal + h_goal\n",
    "\n",
    "    # Push the initial states into their respective frontiers\n",
    "    heappush(frontier_start, (f_start, start_state.tobytes(), g_start, None))\n",
    "    heappush(frontier_goal, (f_goal, goal_state.tobytes(), g_goal, None))\n",
    "\n",
    "    # Dictionaries to store paths and costs for both directions\n",
    "    came_from_start = {start_state.tobytes(): None}\n",
    "    g_score_start = {start_state.tobytes(): 0}\n",
    "\n",
    "    came_from_goal = {goal_state.tobytes(): None}\n",
    "    g_score_goal = {goal_state.tobytes(): 0}\n",
    "\n",
    "    # Sets to keep track of explored states\n",
    "    explored_start = set()\n",
    "    explored_goal = set()\n",
    "\n",
    "# Bidirectional search loop\n",
    "    while frontier_start and frontier_goal:\n",
    "        # Expand from the start frontier\n",
    "        if frontier_start:\n",
    "            _, current_bytes, current_g, parent = heappop(frontier_start)\n",
    "            current_state = np.frombuffer(current_bytes, dtype=start_state.dtype).reshape(start_state.shape)\n",
    "\n",
    "            # Skip if already explored\n",
    "            if current_bytes in explored_start:\n",
    "                continue\n",
    "            explored_start.add(current_bytes)\n",
    "            came_from_start[current_bytes] = parent\n",
    "\n",
    "            # Check if the reverse search has reached this state\n",
    "            if current_bytes in came_from_goal:\n",
    "                cost = len(explored_start) + len(explored_goal)\n",
    "                return reconstruct_path_(came_from_start, came_from_goal, current_bytes), cost\n",
    "\n",
    "            # Expand neighbors\n",
    "            for act in available_actions(current_state):\n",
    "                neighbor = do_action(current_state, act)\n",
    "                neighbor_bytes = neighbor.tobytes()\n",
    "\n",
    "                # Calculate tentive g-score\n",
    "                tentative_g = current_g + 1\n",
    "                if neighbor_bytes not in g_score_start or tentative_g < g_score_start[neighbor_bytes]:\n",
    "                    g_score_start[neighbor_bytes] = tentative_g\n",
    "                    f_score = tentative_g + manhattan_distance(neighbor, goal_state)\n",
    "                    heappush(frontier_start, (f_score, neighbor_bytes, tentative_g, current_bytes))\n",
    "\n",
    "        # Expand from the goal frontier\n",
    "        if frontier_goal:\n",
    "            _, current_bytes, current_g, parent = heappop(frontier_goal)\n",
    "            current_state = np.frombuffer(current_bytes, dtype=goal_state.dtype).reshape(goal_state.shape)\n",
    "\n",
    "            # Skip if already explored\n",
    "            if current_bytes in explored_goal:\n",
    "                continue\n",
    "            explored_goal.add(current_bytes)\n",
    "            came_from_goal[current_bytes] = parent\n",
    "\n",
    "            # Check if the forward search has reached this state\n",
    "            if current_bytes in came_from_start:\n",
    "                cost = len(explored_start) + len(explored_goal)\n",
    "                return reconstruct_path_(came_from_start, came_from_goal, current_bytes), cost\n",
    "\n",
    "            # Expand neighbors\n",
    "            for act in available_actions(current_state):\n",
    "                neighbor = do_action(current_state, act)\n",
    "                neighbor_bytes = neighbor.tobytes()\n",
    "\n",
    "                # Calculate tentive g-score\n",
    "                tentative_g = current_g + 1\n",
    "                if neighbor_bytes not in g_score_goal or tentative_g < g_score_goal[neighbor_bytes]:\n",
    "                    g_score_goal[neighbor_bytes] = tentative_g\n",
    "                    f_score = tentative_g + manhattan_distance(neighbor, start_state)\n",
    "                    heappush(frontier_goal, (f_score, neighbor_bytes, tentative_g, current_bytes))\n",
    "\n",
    "\n",
    "    return None, len(explored_start) + len(explored_goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 10000/10000 [00:00<00:00, 62464.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stato iniziale:\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [ 0 15  5  7]\n",
      " [13  4  9  8]]\n",
      "Quality (number of moves): 48\n",
      "Cost (explored states): 122824\n",
      "Solution Path:\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [ 0 15  5  7]\n",
      " [13  4  9  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [15  0  5  7]\n",
      " [13  4  9  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [15  4  5  7]\n",
      " [13  0  9  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [15  4  5  7]\n",
      " [13  9  0  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [15  4  0  7]\n",
      " [13  9  5  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [15  0  4  7]\n",
      " [13  9  5  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [ 0 15  4  7]\n",
      " [13  9  5  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [13 15  4  7]\n",
      " [ 0  9  5  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [13 15  4  7]\n",
      " [ 9  0  5  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10 14  2  3]\n",
      " [13  0  4  7]\n",
      " [ 9 15  5  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10  0  2  3]\n",
      " [13 14  4  7]\n",
      " [ 9 15  5  8]]\n",
      "[[ 1 11 12  6]\n",
      " [10  2  0  3]\n",
      " [13 14  4  7]\n",
      " [ 9 15  5  8]]\n",
      "[[ 1 11  0  6]\n",
      " [10  2 12  3]\n",
      " [13 14  4  7]\n",
      " [ 9 15  5  8]]\n",
      "[[ 1 11  6  0]\n",
      " [10  2 12  3]\n",
      " [13 14  4  7]\n",
      " [ 9 15  5  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  2 12  0]\n",
      " [13 14  4  7]\n",
      " [ 9 15  5  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  2 12  7]\n",
      " [13 14  4  0]\n",
      " [ 9 15  5  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  2 12  7]\n",
      " [13 14  0  4]\n",
      " [ 9 15  5  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  2 12  7]\n",
      " [13 14  5  4]\n",
      " [ 9 15  0  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  2 12  7]\n",
      " [13 14  5  4]\n",
      " [ 9  0 15  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  2 12  7]\n",
      " [13  0  5  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  2 12  7]\n",
      " [13  5  0  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  2  0  7]\n",
      " [13  5 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  0  2  7]\n",
      " [13  5 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  5  2  7]\n",
      " [13  0 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1 11  6  3]\n",
      " [10  5  2  7]\n",
      " [ 0 13 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1 11  6  3]\n",
      " [ 0  5  2  7]\n",
      " [10 13 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1 11  6  3]\n",
      " [ 5  0  2  7]\n",
      " [10 13 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1  0  6  3]\n",
      " [ 5 11  2  7]\n",
      " [10 13 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1  6  0  3]\n",
      " [ 5 11  2  7]\n",
      " [10 13 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1  6  2  3]\n",
      " [ 5 11  0  7]\n",
      " [10 13 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1  6  2  3]\n",
      " [ 5 11  7  0]\n",
      " [10 13 12  4]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1  6  2  3]\n",
      " [ 5 11  7  4]\n",
      " [10 13 12  0]\n",
      " [ 9 14 15  8]]\n",
      "[[ 1  6  2  3]\n",
      " [ 5 11  7  4]\n",
      " [10 13 12  8]\n",
      " [ 9 14 15  0]]\n",
      "[[ 1  6  2  3]\n",
      " [ 5 11  7  4]\n",
      " [10 13 12  8]\n",
      " [ 9 14  0 15]]\n",
      "[[ 1  6  2  3]\n",
      " [ 5 11  7  4]\n",
      " [10 13 12  8]\n",
      " [ 9  0 14 15]]\n",
      "[[ 1  6  2  3]\n",
      " [ 5 11  7  4]\n",
      " [10  0 12  8]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  6  2  3]\n",
      " [ 5  0  7  4]\n",
      " [10 11 12  8]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  0  2  3]\n",
      " [ 5  6  7  4]\n",
      " [10 11 12  8]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  2  0  3]\n",
      " [ 5  6  7  4]\n",
      " [10 11 12  8]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  2  3  0]\n",
      " [ 5  6  7  4]\n",
      " [10 11 12  8]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  0]\n",
      " [10 11 12  8]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [10 11 12  0]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [10 11  0 12]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [10  0 11 12]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 0 10 11 12]\n",
      " [ 9 13 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [ 0 13 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13  0 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14  0 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15  0]]\n"
     ]
    }
   ],
   "source": [
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "    \n",
    "start_state = state\n",
    "goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\n",
    "# Risolvi il puzzle\n",
    "print(\"Initial state:\")\n",
    "print(state)\n",
    "\n",
    "\n",
    "path, cost = bidirectional_A_star(start_state, goal_state)\n",
    "quality = len(path) - 1  # Quality: Number of moves\n",
    "print(f\"Quality (number of moves): {quality}\")\n",
    "print(f\"Cost (explored states): {cost}\")\n",
    "print(\"Solution Path:\")\n",
    "for step in path:\n",
    "    print(np.frombuffer(step, dtype=start_state.dtype).reshape(start_state.shape))\n",
    "\n",
    "# 8.6s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
